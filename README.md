There are five Python programs here (`-h` for usage):

- Rerank and oracle are used to generate a set of the best translations.
 - `./rerank` chooses the best candidate translations from a k-best list using a linear model.
 - `./oracle` computes a lower bound of BLEU on the development data.

- Pro_sample and pro_weightgenerator are used to calculate the weighting values used in rerank. These
algorithms are taken from the paper "Tuning as Ranking" by Mark Hopkins and Jonathan May (http://bit.ly/19Fk1nX).
 - `./pro_sampler` samples the data from the n-best translations for the given reference translations.
 - `./pro_weightgenerator` runs a linear regression on the data generated by `./prosampler` to obtain the correct weighting for rerank

- Grading is done by calculating the bleu score of the best translations chosen from the n-best list.
 - `./compute-bleu` computes the BLEU score of a set of translations.

The commands are designed to work in a pipeline. For instance, these are valid invocations:

    python pro_sampler | python pro_weightgenerator

    python rerank | python compute-bleu

    python oracle | python compute-bleu

The `data/` directory contains training, devlopment, and test data.

 - `train.src`: Russian source sentences.
 - `train.ref`: English reference sentences.
 - `train.100best`: Candidate translations of `train.src` from a machine translation system.
 - `dev+test.src`: Russian source sentences.
 - `dev.ref`: English references sentences for the first half of `dev+test.src`.
 - `dev+test.100best`: Candidate translations of `dev+test.src`.


